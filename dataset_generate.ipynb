{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating random GORGIAS code\n",
    "\n",
    "The objective of this notebook is to generate an random but syntaxically correct GORGIAS code, we won't give importance to the semantics behind each code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-19T21:35:32.448057Z",
     "start_time": "2025-03-19T21:35:32.443068Z"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "actions = [\n",
    "    # Work-related actions\n",
    "    \"attend_meeting\", \"finish_report\", \"reply_emails\", \"give_presentation\",\n",
    "    \n",
    "    # Social & leisure activities\n",
    "    \"go_to(restaurant)\", \"go_to(cinema)\", \"go_to(park)\", \"go_to(theater)\",\n",
    "    \"visit_family\", \"attend_concert\", \"travel_abroad\", \"go_shopping\",\n",
    "\n",
    "    # Health & exercise\n",
    "    \"go_gym\", \"morning_run\", \"yoga_session\", \"visit_doctor\",\n",
    "\n",
    "    # Daily tasks\n",
    "    \"buy_groceries\", \"clean_house\", \"cook_dinner\", \"read_book\",\n",
    "\n",
    "    # Transportation\n",
    "    \"take_bus\", \"ride_bike\", \"drive_car\", \"book_flight\"\n",
    "]\n",
    "\n",
    "facts = [\n",
    "    # Work-related\n",
    "    \"urgent_deadline\", \"important_meeting\", \"boss_in_office\", \"team_project_due\",\n",
    "\n",
    "    # Personal situations\n",
    "    \"feeling_sick\", \"birthday_today\", \"wedding_anniversary\", \"friend_in_town\", \"medical_appointment\",\n",
    "\n",
    "    # Weather conditions\n",
    "    \"good_weather\", \"rainy_day\", \"snowstorm\", \"hot_day\",\n",
    "\n",
    "    # Time-based events\n",
    "    \"weekend\", \"holiday_season\", \"morning_rush\", \"night_time\",\n",
    "\n",
    "    # Social dynamics\n",
    "    \"invitation_from_friend\", \"family_gathering\", \"new_restaurant_to_try\", \"concert_nearby\",\n",
    "\n",
    "    # Financial considerations\n",
    "    \"low_budget\", \"got_bonus\", \"discount_on_flight\", \"expensive_event\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will classify any GORGIAS as beginner level as the following : \n",
    "- simple arguments with clear rules and priorities\n",
    "- no recursion with minimal dependencies\n",
    "- a maximum of 1 or 2 layers of preferences\n",
    "- no `complement()/2`, abducible or defeasible components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-19T21:35:35.281039Z",
     "start_time": "2025-03-19T21:35:35.276023Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate_beginner_gorgias():\n",
    "    action1, action2 = random.sample(actions, 2)\n",
    "    shared_condition = random.choice(facts)\n",
    "    \n",
    "    remaining_facts = [fact for fact in facts if fact != shared_condition]\n",
    "    p2_condition = random.choice(remaining_facts)\n",
    "\n",
    "    remaining_facts = [fact for fact in remaining_facts if fact != p2_condition]\n",
    "    c2_condition = random.choice(remaining_facts)\n",
    "\n",
    "    rule1 = f\"rule(r1, {action1}, []) :- {shared_condition}.\"\n",
    "    rule2 = f\"rule(r2, {action2}, []) :- {shared_condition}.\"\n",
    "\n",
    "    pref1 = f\"rule(p1, prefer(r1, r2), []).\"\n",
    "\n",
    "    depth = random.choice([1, 2, 3])  # 1 = just p1, 2 = add p2 & c1, 3 = full depth\n",
    "\n",
    "    rules = [rule1, rule2, pref1]\n",
    "\n",
    "    if depth >= 2:\n",
    "        pref2 = f\"rule(p2, prefer(r2, r1), []) :- {p2_condition}.\"\n",
    "        conflict1 = \"rule(c1, prefer(p2, p1), []).\"\n",
    "        rules.extend([pref2, conflict1])\n",
    "\n",
    "    if depth == 3:\n",
    "        conflict2 = f\"rule(c2, prefer(p1, p2), []) :- {c2_condition}.\"\n",
    "        conflict3 = \"rule(c3, prefer(c2, c1), []).\"\n",
    "        rules.extend([conflict2, conflict3])\n",
    "\n",
    "    return \"\\n\".join(rules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-19T21:35:37.572166Z",
     "start_time": "2025-03-19T21:35:37.569269Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Example 1 ###\n",
      "rule(r1, visit_doctor, []) :- weekend.\n",
      "rule(r2, cook_dinner, []) :- weekend.\n",
      "rule(p1, prefer(r1, r2), []).\n",
      "\n",
      "### Example 2 ###\n",
      "rule(r1, give_presentation, []) :- invitation_from_friend.\n",
      "rule(r2, go_gym, []) :- invitation_from_friend.\n",
      "rule(p1, prefer(r1, r2), []).\n",
      "\n",
      "### Example 3 ###\n",
      "rule(r1, book_flight, []) :- night_time.\n",
      "rule(r2, buy_groceries, []) :- night_time.\n",
      "rule(p1, prefer(r1, r2), []).\n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_examples = 3\n",
    "gorgias_examples = [generate_beginner_gorgias() for _ in range(num_examples)]\n",
    "\n",
    "for i, example in enumerate(gorgias_examples, 1):\n",
    "    print(f\"### Example {i} ###\\n{example}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the intermediate level we will add the `complement()/2`, `neg()/1`, having multi-level preference, more rules (for easy belief theories), for the preference we can add multiple conditions instead of one.\n",
    "\n",
    "A good intermediate level should be the example of Allow/deny call :\n",
    "\n",
    "```prolog\n",
    ":- dynamic phone_call/0, at_work/0, family_member/1, at_meeting/0.\n",
    "rule(r1(Call), allow(Call), []):- phone_call.\n",
    "rule(r2(Call), deny(Call), []):- phone_call.\n",
    "% Do we need to specify again the phone_call for p1 and p2 ???\n",
    "rule(p1(Call), prefer(r1(Call), r2(Call)), []):- phone_call.\n",
    "rule(p2(Call), prefer(r2(Call), r1(Call)), []):- phone_call , at_work.\n",
    "\n",
    "rule(c1(Call), prefer(p2(Call), p1(Call)), []).\n",
    "% And here too for at_work ?\n",
    "rule(c2(Call), prefer(p1(Call), p2(Call)), []):- phone_call , at_work, familly_member(Call).\n",
    "\n",
    "rule(c3(Call), prefer(c2(Call), c1(Call)), []).\n",
    "\n",
    "rule(c4(Call), prefer(c1(Call), c2(Call)), []):- phone_call , at_work, familly_member(Call), at_meeting.\n",
    "\n",
    "rule(c5(Call), prefer(c4(Call), c3(Call)), []).\n",
    "\n",
    "complement(deny(Call), allow(Call)).\n",
    "complement(allow(Call), deny(Call)).\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WIP\n",
    "def generate_intermediate_gorgias():\n",
    "    action1, action2 = random.sample(actions, 2)\n",
    "    \n",
    "    fact1 = random.choice(facts)\n",
    "    remaining_facts = [f for f in facts if f != fact1]\n",
    "    fact2 = random.choice(remaining_facts)\n",
    "    remaining_facts = [f for f in remaining_facts if f != fact2]\n",
    "    fact3 = random.choice(remaining_facts)\n",
    "    \n",
    "    rules = []\n",
    "    \n",
    "    rule1 = f\"rule(r1, {action1}, []) :- {fact1}.\"\n",
    "    rule2 = f\"rule(r2, {action2}, []) :- {fact1}.\"\n",
    "    \n",
    "    pref1 = f\"rule(p1, prefer(r1, r2), []) :- {fact1}, {fact3}.\"\n",
    "    pref2 = f\"rule(p2, prefer(r2, r1), []) :- {fact2}, {fact3}.\"\n",
    "    \n",
    "    conflict1 = \"rule(c1, prefer(p2, p1), []).\"\n",
    "    conflict2 = f\"rule(c2, prefer(p1, p2), []) :- {fact2}, neg({fact3}).\"\n",
    "    conflict3 = \"rule(c3, prefer(c2, c1), []).\"\n",
    "    \n",
    "    complement1 = f\"complement({action2}, {action1}).\"\n",
    "    complement2 = f\"complement({action1}, {action2}).\"\n",
    "    \n",
    "    rules.extend([rule1, rule2, pref1, pref2, conflict1, conflict2, conflict3, complement1, complement2])\n",
    "    \n",
    "    return \"\\n\".join(rules)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code automates the creation of 100 Gorgias code examples and saves them in a structured CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-19T21:23:59.222064Z",
     "start_time": "2025-03-19T21:23:59.217654Z"
    }
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "num_examples = 100\n",
    "\n",
    "gorgias_examples = [generate_beginner_gorgias() for _ in range(num_examples)]\n",
    "\n",
    "with open(\"gorgias_examples.csv\", \"w\", newline=\"\", encoding=\"utf-8\") as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow([\"Example Number\", \"Gorgias Code\"])\n",
    "    for i, example in enumerate(gorgias_examples, start=1):\n",
    "        writer.writerow([i, example])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code reads a CSV file containing Gorgias code examples, translates each example into clear English using the OpenAI Chat API, and then writes the original code along with its translation into a new CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-19T21:45:49.633034Z",
     "start_time": "2025-03-19T21:42:38.474982Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing example 1...\n",
      "Processing example 2...\n",
      "Processing example 3...\n",
      "Processing example 4...\n",
      "Processing example 5...\n",
      "Processing example 6...\n",
      "Processing example 7...\n",
      "Processing example 8...\n",
      "Processing example 9...\n",
      "Processing example 10...\n",
      "Processing example 11...\n",
      "Processing example 12...\n",
      "Processing example 13...\n",
      "Processing example 14...\n",
      "Processing example 15...\n",
      "Processing example 16...\n",
      "Processing example 17...\n",
      "Processing example 18...\n",
      "Processing example 19...\n",
      "Processing example 20...\n",
      "Processing example 21...\n",
      "Processing example 22...\n",
      "Processing example 23...\n",
      "Processing example 24...\n",
      "Processing example 25...\n",
      "Processing example 26...\n",
      "Processing example 27...\n",
      "Processing example 28...\n",
      "Processing example 29...\n",
      "Processing example 30...\n",
      "Processing example 31...\n",
      "Processing example 32...\n",
      "Processing example 33...\n",
      "Processing example 34...\n",
      "Processing example 35...\n",
      "Processing example 36...\n",
      "Processing example 37...\n",
      "Processing example 38...\n",
      "Processing example 39...\n",
      "Processing example 40...\n",
      "Processing example 41...\n",
      "Processing example 42...\n",
      "Processing example 43...\n",
      "Processing example 44...\n",
      "Processing example 45...\n",
      "Processing example 46...\n",
      "Processing example 47...\n",
      "Processing example 48...\n",
      "Processing example 49...\n",
      "Processing example 50...\n",
      "Processing example 51...\n",
      "Processing example 52...\n",
      "Processing example 53...\n",
      "Processing example 54...\n",
      "Processing example 55...\n",
      "Processing example 56...\n",
      "Processing example 57...\n",
      "Processing example 58...\n",
      "Processing example 59...\n",
      "Processing example 60...\n",
      "Processing example 61...\n",
      "Processing example 62...\n",
      "Processing example 63...\n",
      "Processing example 64...\n",
      "Processing example 65...\n",
      "Processing example 66...\n",
      "Processing example 67...\n",
      "Processing example 68...\n",
      "Processing example 69...\n",
      "Processing example 70...\n",
      "Processing example 71...\n",
      "Processing example 72...\n",
      "Processing example 73...\n",
      "Processing example 74...\n",
      "Processing example 75...\n",
      "Processing example 76...\n",
      "Processing example 77...\n",
      "Processing example 78...\n",
      "Processing example 79...\n",
      "Processing example 80...\n",
      "Processing example 81...\n",
      "Processing example 82...\n",
      "Processing example 83...\n",
      "Processing example 84...\n",
      "Processing example 85...\n",
      "Processing example 86...\n",
      "Processing example 87...\n",
      "Processing example 88...\n",
      "Processing example 89...\n",
      "Processing example 90...\n",
      "Processing example 91...\n",
      "Processing example 92...\n",
      "Processing example 93...\n",
      "Processing example 94...\n",
      "Processing example 95...\n",
      "Processing example 96...\n",
      "Processing example 97...\n",
      "Processing example 98...\n",
      "Processing example 99...\n",
      "Processing example 100...\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import openai\n",
    "import time\n",
    "\n",
    "openai.api_key = \"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\"\n",
    "\n",
    "def translate_gorgias_to_nl(gorgias_code):\n",
    "\n",
    "    prompt = f\"Please translate the following Gorgias program into clear English, without including any additional built-in rules or extra explanations:\\n\\n{gorgias_code}\\n\"\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ]\n",
    "\n",
    "    try:\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=messages,\n",
    "            temperature=0.5,\n",
    "            max_tokens=300\n",
    "        )\n",
    "        translation = response.choices[0].message['content'].strip()\n",
    "    except Exception as e:\n",
    "        print(f\"Error during API call: {e}\")\n",
    "        translation = \"Error in translation.\"\n",
    "\n",
    "    return translation\n",
    "\n",
    "input_file = \"gorgias_examples.csv\"\n",
    "\n",
    "output_file = \"gorgias_nl_pairs.csv\"\n",
    "\n",
    "with open(input_file, \"r\", encoding=\"utf-8\") as infile, \\\n",
    "     open(output_file, \"w\", newline=\"\", encoding=\"utf-8\") as outfile:\n",
    "\n",
    "    reader = csv.DictReader(infile)\n",
    "    fieldnames = [\"Example Number\", \"Gorgias Code\", \"NL Translation\"]\n",
    "    writer = csv.DictWriter(outfile, fieldnames=fieldnames)\n",
    "\n",
    "    writer.writeheader()\n",
    "\n",
    "    for row in reader:\n",
    "        example_number = row[\"Example Number\"]\n",
    "        gorgias_code = row[\"Gorgias Code\"]\n",
    "\n",
    "        print(f\"Processing example {example_number}...\")\n",
    "        nl_translation = translate_gorgias_to_nl(gorgias_code)\n",
    "\n",
    "        writer.writerow({\n",
    "            \"Example Number\": example_number,\n",
    "            \"Gorgias Code\": gorgias_code,\n",
    "            \"NL Translation\": nl_translation\n",
    "        })\n",
    "\n",
    "        time.sleep(1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code does the same thing as the previous one, but with an example in the prompt.  This results in significantly improved, more human-like, and syntactically correct responses from the OpenAI API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-19T21:55:02.710147Z",
     "start_time": "2025-03-19T21:51:59.921526Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing example 1...\n",
      "Processing example 2...\n",
      "Processing example 3...\n",
      "Processing example 4...\n",
      "Processing example 5...\n",
      "Processing example 6...\n",
      "Processing example 7...\n",
      "Processing example 8...\n",
      "Processing example 9...\n",
      "Processing example 10...\n",
      "Processing example 11...\n",
      "Processing example 12...\n",
      "Processing example 13...\n",
      "Processing example 14...\n",
      "Processing example 15...\n",
      "Processing example 16...\n",
      "Processing example 17...\n",
      "Processing example 18...\n",
      "Processing example 19...\n",
      "Processing example 20...\n",
      "Processing example 21...\n",
      "Processing example 22...\n",
      "Processing example 23...\n",
      "Processing example 24...\n",
      "Processing example 25...\n",
      "Processing example 26...\n",
      "Processing example 27...\n",
      "Processing example 28...\n",
      "Processing example 29...\n",
      "Processing example 30...\n",
      "Processing example 31...\n",
      "Processing example 32...\n",
      "Processing example 33...\n",
      "Processing example 34...\n",
      "Processing example 35...\n",
      "Processing example 36...\n",
      "Processing example 37...\n",
      "Processing example 38...\n",
      "Processing example 39...\n",
      "Processing example 40...\n",
      "Processing example 41...\n",
      "Processing example 42...\n",
      "Processing example 43...\n",
      "Processing example 44...\n",
      "Processing example 45...\n",
      "Processing example 46...\n",
      "Processing example 47...\n",
      "Processing example 48...\n",
      "Processing example 49...\n",
      "Processing example 50...\n",
      "Processing example 51...\n",
      "Processing example 52...\n",
      "Processing example 53...\n",
      "Processing example 54...\n",
      "Processing example 55...\n",
      "Processing example 56...\n",
      "Processing example 57...\n",
      "Processing example 58...\n",
      "Processing example 59...\n",
      "Processing example 60...\n",
      "Processing example 61...\n",
      "Processing example 62...\n",
      "Processing example 63...\n",
      "Processing example 64...\n",
      "Processing example 65...\n",
      "Processing example 66...\n",
      "Processing example 67...\n",
      "Processing example 68...\n",
      "Processing example 69...\n",
      "Processing example 70...\n",
      "Processing example 71...\n",
      "Processing example 72...\n",
      "Processing example 73...\n",
      "Processing example 74...\n",
      "Processing example 75...\n",
      "Processing example 76...\n",
      "Processing example 77...\n",
      "Processing example 78...\n",
      "Processing example 79...\n",
      "Processing example 80...\n",
      "Processing example 81...\n",
      "Processing example 82...\n",
      "Processing example 83...\n",
      "Processing example 84...\n",
      "Processing example 85...\n",
      "Processing example 86...\n",
      "Processing example 87...\n",
      "Processing example 88...\n",
      "Processing example 89...\n",
      "Processing example 90...\n",
      "Processing example 91...\n",
      "Processing example 92...\n",
      "Processing example 93...\n",
      "Processing example 94...\n",
      "Processing example 95...\n",
      "Processing example 96...\n",
      "Processing example 97...\n",
      "Processing example 98...\n",
      "Processing example 99...\n",
      "Processing example 100...\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import openai\n",
    "import time\n",
    "\n",
    "openai.api_key = \"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\"\n",
    "\n",
    "def translate_gorgias_to_nl(gorgias_code):\n",
    "\n",
    "    prompt = f\"\"\"The Gorgias program :\n",
    "\n",
    "rule(r1, go_out, []) :- nice_weather.\n",
    "rule(r2, stay_home, []) :- nice_weather.\n",
    "rule(p1, prefer(r1, r2), []).\n",
    "rule(p2, prefer(r2, r1), []) :- nice_movie_on_tv.\n",
    "rule(c1, prefer(p2, p1), []).\n",
    "\n",
    "translates to English as \"When it is nice weather I can go out or stay home. Generally, I prefer to go out but if there is a nice movie on TV I prefer to stay home.\"\n",
    "Please translate the following Gorgias program into clear English, without including any additional built-in rules or extra explanations:\\n\\n{gorgias_code}\\n\"\"\"\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ]\n",
    "\n",
    "    try:\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=messages,\n",
    "            temperature=0.5,\n",
    "            max_tokens=300\n",
    "        )\n",
    "        translation = response.choices[0].message['content'].strip()\n",
    "    except Exception as e:\n",
    "        print(f\"Error during API call: {e}\")\n",
    "        translation = \"Error in translation.\"\n",
    "\n",
    "    return translation\n",
    "\n",
    "input_file = \"gorgias_examples.csv\"\n",
    "\n",
    "output_file = \"gorgias_nl_pairs_modified_prompt.csv\"\n",
    "\n",
    "with open(input_file, \"r\", encoding=\"utf-8\") as infile, \\\n",
    "     open(output_file, \"w\", newline=\"\", encoding=\"utf-8\") as outfile:\n",
    "\n",
    "    reader = csv.DictReader(infile)\n",
    "    fieldnames = [\"Example Number\", \"Gorgias Code\", \"NL Translation\"]\n",
    "    writer = csv.DictWriter(outfile, fieldnames=fieldnames)\n",
    "\n",
    "    writer.writeheader()\n",
    "\n",
    "    for row in reader:\n",
    "        example_number = row[\"Example Number\"]\n",
    "        gorgias_code = row[\"Gorgias Code\"]\n",
    "\n",
    "        print(f\"Processing example {example_number}...\")\n",
    "        nl_translation = translate_gorgias_to_nl(gorgias_code)\n",
    "\n",
    "        writer.writerow({\n",
    "            \"Example Number\": example_number,\n",
    "            \"Gorgias Code\": gorgias_code,\n",
    "            \"NL Translation\": nl_translation\n",
    "        })\n",
    "\n",
    "        time.sleep(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
